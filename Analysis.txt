When deciding upon hyperparameters, I felt that the channel numbers and layer numbers provided by the MNISTCnv.py file were adequate, but perhaps required some regularization. 
I tried multiple dropout rates in conjunction with l1/l2 kernel/activity regularization, and found that simply adding a dropout rate of 1.0 with no other regularization was the best optimization.

In regards to the augmentation I chose, I found that some of the original data was skewed by a marginal amount, but found very little cases of rotation. My tests verified this hypothesis, and I finalized upon height/width axis shifts and a rotation range of 1 degree. However, my test accuracy was missing the 99.50% mark. To correct this, I tweaked the values of my rotation and axis shift ranges and added shearing and zoom augmentations. Finally, I was able to beat the 9950 requirement, by a whopping 11 points to obtain 9961. It took quite a lot of runs to obtain this accuracy while maintaining the augmentation.